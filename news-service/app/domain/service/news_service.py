from collections import Counter
import requests
from bs4 import BeautifulSoup
import logging
from wordcloud import WordCloud # ì›Œë“œí´ë¼ìš°ë“œ ì„í¬íŠ¸
import matplotlib # matplotlib ì„í¬íŠ¸
matplotlib.use('Agg') # GUI ë°±ì—”ë“œ ë¹„í™œì„±í™”
import matplotlib.pyplot as plt # pyplot ì„í¬íŠ¸ (í°íŠ¸ ê²½ë¡œ ì§€ì • ë“±ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŒ)
import io # ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì„í¬íŠ¸
import base64 # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸

logger = logging.getLogger("news_service")

# í•œê¸€ í°íŠ¸ ê²½ë¡œ (Dockerfileì— ì„¤ì¹˜ëœ ê²½ë¡œì— ë§ê²Œ ì¡°ì • í•„ìš”)
# Dockerfileì—ì„œ fonts-nanumì„ ì„¤ì¹˜í–ˆë‹¤ë©´ ì¼ë°˜ì ìœ¼ë¡œ ì•„ë˜ ê²½ë¡œ ì¤‘ í•˜ë‚˜ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì‹¤ì œ ê²½ë¡œëŠ” Docker ì´ë¯¸ì§€ ë‚´ë¶€ì—ì„œ `fc-list :lang=ko` ëª…ë ¹ ë“±ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.
FONT_PATH = 'app/static/fonts/NanumGothic.ttf' # í°íŠ¸ ê²½ë¡œë¥¼ í”„ë¡œì íŠ¸ ë‚´ë¶€ ê²½ë¡œë¡œ ë³€ê²½

class NewsService:
    def __init__(self):
        pass

    def get_news(self, company_name: str):
        base_url = "https://search.naver.com/search.naver"
        params = {
            "where": "news",
            "ie": "utf8",
            "sm": "nws_hty",
            "query": company_name
        }
        headers = {
            "User-Agent": "Mozilla/5.0"
        }

        try:
            response = requests.get(base_url, headers=headers, params=params)
            logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ Response: {response.text}")
            response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
        except requests.RequestException as e:
            logger.error(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return {"error": f"ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {str(e)}"}

        soup = BeautifulSoup(response.text, "html.parser")
        logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ Soup: {soup}")
        
        # ì œëª© ìš”ì†Œ ì°¾ê¸°
        items = soup.select("span[class='sds-comps-text sds-comps-text-ellipsis-1 sds-comps-text-type-headline1']")
        logger.info(f"ğŸƒâœ¨ğŸ‰Items: {len(items)}")
        
        # ë¶€ëª¨ ìš”ì†Œë¥¼ íƒìƒ‰í•˜ì—¬ ë§í¬ ì¶”ì¶œ
        news_list = []
        for item in items[:5]:  # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ë§Œ ì¶”ì¶œ
            title = item.get_text(strip=True)
            
            # ì œëª© ìš”ì†Œì˜ ë¶€ëª¨ ì¤‘ì—ì„œ a íƒœê·¸ ì°¾ê¸°
            parent_element = item.parent
            while parent_element and parent_element.name != 'a' and parent_element.name != 'html':
                parent_element = parent_element.parent
            
            link = None
            if parent_element and parent_element.name == 'a':
                link = parent_element.get('href')
                logger.info(f"ğŸ”— ë§í¬ ì¶”ì¶œ ì„±ê³µ: {link}")
            else:
                logger.warning(f"âš ï¸ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {title}")
            
            news_list.append({
                "title": title,
                "link": link
            })
        
        logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ News List: {news_list}")

        # ë§í¬ë§Œ ì¶”ì¶œí•´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬
        links = [news['link'] for news in news_list if news.get('link')]
        print("ğŸ”— ì¶”ì¶œëœ ë§í¬ ëª©ë¡:")
        for link in links:
            print(link)

        return {
            "company": company_name,
            "news": news_list
        }



    def get_news_content(self, url: str) -> str:
        """ê° ë‰´ìŠ¤ ë§í¬ì—ì„œ ë³¸ë¬¸ í¬ë¡¤ë§"""
        try:
            response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.content.decode('utf-8', 'replace'), "html.parser") # utf-8 ë””ì½”ë”© ëª…ì‹œ

            # ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ì„ íƒì (ë‹¤ì–‘í•œ êµ¬ì¡°ì— ëŒ€ì‘)
            # ìš°ì„ ìˆœìœ„: #articleBodyContents (êµ¬ë²„ì „), #dic_area (ì¼ë°˜), article (HTML5 ì‹œë§¨í‹± íƒœê·¸)
            content_selectors = [
                '#articleBodyContents',
                '#dic_area',
                'article#dic_area', # ì¢€ ë” ëª…í™•í•œ ì„ íƒ
                'div.article_body', # ë‹¤ë¥¸ ì–¸ë¡ ì‚¬ í¬ë§·
                'div.newsct_body', # ë‹¤ë¥¸ ì–¸ë¡ ì‚¬ í¬ë§·
                'article'
            ]
            article = None
            for selector in content_selectors:
                article = soup.select_one(selector)
                if article:
                    break
            
            content = ""
            if article:
                # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (ê´‘ê³ , ê´€ë ¨ë‰´ìŠ¤ ë“±)
                tags_to_remove = ['script', 'style', 'iframe', 'footer', 'header', 'aside', '.link_news', '.promotion', '.journalist_info']
                for tag_selector in tags_to_remove:
                    for unwanted_tag in article.select(tag_selector):
                        unwanted_tag.decompose()
                content = article.get_text(separator="\n", strip=True)
            else:
                content = "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ (ì„ íƒì ë¶ˆì¼ì¹˜)"
            
            # logger.info(f"ğŸ“„ URL '{url}' ë³¸ë¬¸ ì¶”ì¶œ ê²°ê³¼: {content[:200]}...") # ë„ˆë¬´ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ ë¡œê¹…
            return content

        except requests.Timeout:
            logger.error(f"âŒ ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œê°„ ì´ˆê³¼: {url}")
            return "ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œê°„ ì´ˆê³¼"
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ({url}): {str(e)}")
            return f"ë³¸ë¬¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}"

    def analyze_esg_keywords(self, contents: list) -> dict:
        """ë‰´ìŠ¤ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ESG í‚¤ì›Œë“œ ë“±ì¥ ë¹ˆë„ ë¶„ì„"""
        esg_keywords_path = "app/domain/service/esg_keywords.txt" # ê²½ë¡œ ìˆ˜ì •
        try:
            with open(esg_keywords_path, "r", encoding="utf-8") as file:
                esg_keywords = [line.strip() for line in file.readlines() if line.strip()]
            logger.info(f"ğŸ”‘ ESG í‚¤ì›Œë“œ {len(esg_keywords)}ê°œ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ: {esg_keywords_path}")
        except FileNotFoundError:
            logger.error(f"âŒ ESG í‚¤ì›Œë“œ íŒŒì¼({esg_keywords_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"error": f"ESG í‚¤ì›Œë“œ íŒŒì¼({esg_keywords_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}


        combined_text = " ".join(contents)
        if not combined_text.strip():
            logger.warning("âš ï¸ ë¶„ì„í•  í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {}
            
        word_freq = Counter()

        for word in esg_keywords:
            count = combined_text.count(word)
            if count > 0:
                word_freq[word] = count
        
        logger.info(f"ğŸ“Š ESG í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ ì™„ë£Œ: {dict(word_freq)}")
        return dict(word_freq)

    def generate_wordcloud_image(self, word_freq: dict) -> str:
        """
        ë‹¨ì–´ ë¹ˆë„ìˆ˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ 
        Base64ë¡œ ì¸ì½”ë”©ëœ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if not word_freq:
            logger.info("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return "" # ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€/ê¸°ë³¸ ì´ë¯¸ì§€ Base64 ë°˜í™˜ ê°€ëŠ¥

        try:
            # WordCloud ê°ì²´ ìƒì„±
            # Macì—ì„œ Brewë¡œ fontconfig ì„¤ì¹˜ ì‹œ /opt/homebrew/etc/fonts/conf.d ê²½ë¡œì— í°íŠ¸ ì„¤ì •ì´ ìˆì„ ìˆ˜ ìˆìŒ
            # Dockerfileì— ì§€ì •ëœ í°íŠ¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            wc = WordCloud(
                font_path=FONT_PATH,
                width=800,
                height=400,
                background_color="white",
                max_words=100 # í‘œì‹œí•  ìµœëŒ€ ë‹¨ì–´ ìˆ˜
            ).generate_from_frequencies(word_freq)

            # ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜ í›„ ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ì— ì €ì¥
            img_byte_arr = io.BytesIO()
            wc.to_image().save(img_byte_arr, format='PNG')
            img_byte_arr = img_byte_arr.getvalue()

            # Base64ë¡œ ì¸ì½”ë”©
            img_base64 = base64.b64encode(img_byte_arr).decode('utf-8')
            logger.info("ğŸ–¼ï¸ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ìƒì„± ë° Base64 ì¸ì½”ë”© ì„±ê³µ")
            return img_base64
        except Exception as e:
            # í°íŠ¸ ê²½ë¡œ ë¬¸ì œ ë°œìƒ ì‹œ ì—¬ê¸°ì„œ ì—ëŸ¬ ë¡œê¹… ê°€ëŠ¥
            logger.error(f"âŒ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            logger.error(f"â„¹ï¸ ì‚¬ìš©ëœ í°íŠ¸ ê²½ë¡œ: {FONT_PATH}")
            # í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° OSError: cannot open resource ë°œìƒ ê°€ëŠ¥
            if "cannot open resource" in str(e) or "No such file or directory" in str(e):
                 logger.error("ğŸ†˜ í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Dockerfileì— í°íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€, FONT_PATHê°€ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”.")
            return "" # ë˜ëŠ” ì—ëŸ¬ ì²˜ë¦¬ì— ë§ëŠ” ê°’ ë°˜í™˜