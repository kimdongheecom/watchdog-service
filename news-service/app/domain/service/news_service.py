from collections import Counter
import requests
from bs4 import BeautifulSoup
import logging
from wordcloud import WordCloud # ì›Œë“œí´ë¼ìš°ë“œ ì„í¬íŠ¸
import matplotlib # matplotlib ì„í¬íŠ¸
matplotlib.use('Agg') # GUI ë°±ì—”ë“œ ë¹„í™œì„±í™”
import matplotlib.pyplot as plt # pyplot ì„í¬íŠ¸ (í°íŠ¸ ê²½ë¡œ ì§€ì • ë“±ì— ì‚¬ìš©ë  ìˆ˜ ìˆìŒ)
import io # ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì„í¬íŠ¸
import base64 # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ê¸° ìœ„í•´ ì„í¬íŠ¸

# ğŸ”§ [Selenium ê´€ë ¨ ì¶”ê°€ import]
import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService

logger = logging.getLogger("news_service")

# í•œê¸€ í°íŠ¸ ê²½ë¡œ (Dockerfileì— ì„¤ì¹˜ëœ ê²½ë¡œì— ë§ê²Œ ì¡°ì • í•„ìš”)
# Dockerfileì—ì„œ fonts-nanumì„ ì„¤ì¹˜í–ˆë‹¤ë©´ ì¼ë°˜ì ìœ¼ë¡œ ì•„ë˜ ê²½ë¡œ ì¤‘ í•˜ë‚˜ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# ì‹¤ì œ ê²½ë¡œëŠ” Docker ì´ë¯¸ì§€ ë‚´ë¶€ì—ì„œ `fc-list :lang=ko` ëª…ë ¹ ë“±ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.
FONT_PATH = 'app/static/fonts/NanumGothic.ttf' # í°íŠ¸ ê²½ë¡œë¥¼ í”„ë¡œì íŠ¸ ë‚´ë¶€ ê²½ë¡œë¡œ ë³€ê²½

class NewsService:
    def __init__(self):
        pass

    def get_news(self, company_name: str):
        base_url = "https://search.naver.com/search.naver"
        params = {
            "where": "news",
            "ie": "utf8",
            "sm": "nws_hty",
            "query": company_name
        }
        headers = {
            "User-Agent": "Mozilla/5.0"
        }

        try:
            response = requests.get(base_url, headers=headers, params=params)
            logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ Response: {response.text}")
            response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
        except requests.RequestException as e:
            logger.error(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
            return {"error": f"ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì²­ ì‹¤íŒ¨: {str(e)}"}

        soup = BeautifulSoup(response.text, "html.parser")
        logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ Soup: {soup}")
        
        # ì œëª© ìš”ì†Œ ì°¾ê¸°
        items = soup.select("span[class='sds-comps-text sds-comps-text-ellipsis-1 sds-comps-text-type-headline1']")
        logger.info(f"ğŸƒâœ¨ğŸ‰Items: {len(items)}")
        
        # ë¶€ëª¨ ìš”ì†Œë¥¼ íƒìƒ‰í•˜ì—¬ ë§í¬ ì¶”ì¶œ
        news_list = []
        for item in items[:5]:  # ìƒìœ„ 5ê°œ ë‰´ìŠ¤ë§Œ ì¶”ì¶œ
            title = item.get_text(strip=True)
            
            # ì œëª© ìš”ì†Œì˜ ë¶€ëª¨ ì¤‘ì—ì„œ a íƒœê·¸ ì°¾ê¸°
            parent_element = item.parent
            while parent_element and parent_element.name != 'a' and parent_element.name != 'html':
                parent_element = parent_element.parent
            
            link = None
            if parent_element and parent_element.name == 'a':
                link = parent_element.get('href')
                logger.info(f"ğŸ”— ë§í¬ ì¶”ì¶œ ì„±ê³µ: {link}")
            else:
                logger.warning(f"âš ï¸ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {title}")
            
            news_list.append({
                "title": title,
                "link": link
            })
        
        logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ News List: {news_list}")

        # ë§í¬ë§Œ ì¶”ì¶œí•´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬
        links = [news['link'] for news in news_list if news.get('link')]
        print("ğŸ”— ì¶”ì¶œëœ ë§í¬ ëª©ë¡:")
        for link in links:
            print(link)
        
        link1 = links[0]
        content = self.crawl_with_selenium(link1)
        print("ğŸ”— ì¶”ì¶œëœ ì»¨í…ì¸  ë‚´ìš©:",content)

  
    
    def crawl_with_selenium(self, link: str) -> str:
        """Seleniumì„ ì´ìš©í•œ ë‰´ìŠ¤ ë³¸ë¬¸ ë™ì  í¬ë¡¤ë§ (Docker ìµœì í™”)"""
        
        # ChromeDriverëŠ” Docker ë‚´ë¶€ PATHì— ìˆê±°ë‚˜, ëª…ì‹œì  ê²½ë¡œ ì‚¬ìš©:
        CHROMEDRIVER_IN_CONTAINER_PATH = "/usr/bin/chromedriver" 

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--no-sandbox")  # Dockerì—ì„œ rootë¡œ ì‹¤í–‰ ì‹œ í•„ìˆ˜
        options.add_argument("--disable-dev-shm-usage")  # ì œí•œëœ ë¦¬ì†ŒìŠ¤ ë¬¸ì œ í•´ê²°
        options.add_argument("--disable-gpu") # headless ëª¨ë“œì—ì„œ ê¶Œì¥
        options.add_argument("--window-size=1920x1080") # ë°˜ì‘í˜• ì‚¬ì´íŠ¸ì— ë„ì›€ë  ìˆ˜ ìˆìŒ
        
        # ì´ User-Agentë¥¼ Dockerfileì˜ CHROME_VERSIONê³¼ ì¼ì¹˜ì‹œí‚¤ë©´ ì¢‹ìŒ
        # ì˜ˆ: "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.6478.126 Safari/537.36"
        # ê°„ë‹¨í•˜ê²Œ ì¼ë°˜ì ì¸ ê²ƒì„ ì‚¬ìš©í•´ë„ ë¬´ë°©:
        options.add_argument("user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36")
        
        # chromedriverê°€ PATHì— ìˆë‹¤ë©´ Service()ì— executable_pathê°€ í•„ìš” ì—†ì„ ìˆ˜ ìˆìŒ
        # service = ChromeService()
        # í•˜ì§€ë§Œ Docker í™˜ê²½ì—ì„œëŠ” ëª…ì‹œí•˜ëŠ” ê²ƒì´ ë” ì•ˆì „:
        service = ChromeService(executable_path=CHROMEDRIVER_IN_CONTAINER_PATH)
        
        driver = None # finally ë¸”ë¡ì„ ìœ„í•´ driverë¥¼ Noneìœ¼ë¡œ ì´ˆê¸°í™”
        try:
            driver = webdriver.Chrome(service=service, options=options)
            logger.info(f"ğŸš€ Selenium WebDriver ì‹œì‘ë¨. URL: {link}")
            driver.get(link)
            logger.info(f"ğŸ‡ğŸ†ğŸ‹ğŸ Selenium WebDriver ì‹œì‘ë¨. URL: {link}")
            
            # JavaScript ë¡œë“œ ì‹œê°„ ë¶€ì—¬, í•„ìš”ì— ë”°ë¼ ì¡°ì •
            # time.sleep(3) # ë³µì¡í•œ í˜ì´ì§€ì—ëŠ” ë„ˆë¬´ ì§§ì„ ìˆ˜ ìˆìŒ
            # AJAXê°€ ë§ì€ ì‚¬ì´íŠ¸ì˜ ê²½ìš° WebDriverWait í•„ìš”í•  ìˆ˜ ìˆìŒ
            driver.implicitly_wait(5) # ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ìµœëŒ€ 5ì´ˆ ëŒ€ê¸°
            logger.info(f"ğŸ§¶ğŸ§¥ğŸ¥½ Selenium WebDriver ì‹œì‘ë¨. URL: {link}")

            # ë‰´ìŠ¤ ì½˜í…ì¸ ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì„ íƒì ì‹œë„
            selectors = [
                'div#dic_area',             # ë„¤ì´ë²„ ë‰´ìŠ¤ ì¼ë°˜
                'article#dic_area',         # ì¢€ ë” êµ¬ì²´ì ì¸ ë„¤ì´ë²„ ë‰´ìŠ¤
                '#articleBodyContents',     # êµ¬í˜• ë„¤ì´ë²„ ë‰´ìŠ¤
                'div.article_body',         # ë§ì€ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ ê³µí†µ
                'div.newsct_article',       # ë‹¤ë¥¸ ì¼ë°˜ì ì¸ íŒ¨í„´
                'div.news_view',            # ë˜ ë‹¤ë¥¸ íŒ¨í„´
                'div#newsct_article',       # íŠ¹ì • ID
                'section.article-view',     # ì¼ë°˜ì ì¸ section íƒœê·¸
                'article',                  # ì¼ë°˜ HTML5 article íƒœê·¸
                'main'                      # ì¼ë°˜ HTML5 main íƒœê·¸
            ]
            logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ ì„ íƒì ì‹œë„ ì¤‘: {selectors[0]}")
            content_text = ""
            for i, selector in enumerate(selectors):
                try:
                    # logger.debug(f"ì„ íƒì ì‹œë„ ì¤‘ [{i+1}/{len(selectors)}]: '{selector}' (URL: {link})")
                    # ì¦‰ì‹œ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ì¡´ì¬ í™•ì¸ì„ ìœ„í•´ find_elements ì‚¬ìš©
                    elements = driver.find_elements("css selector", selector)
                    if elements:
                        # ë°œê²¬ëœ ì²« ë²ˆì§¸ ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì£¼ìš” ë‚´ìš©ìœ¼ë¡œ ê°€ì •)
                        # ì¼ë¶€ í˜ì´ì§€ëŠ” ì—¬ëŸ¬ ê°œê°€ ì¼ì¹˜í•  ìˆ˜ ìˆìœ¼ë©°, ì—¬ê¸°ì„œëŠ” ë¹„ì–´ìˆì§€ ì•Šì€ ì²« ë²ˆì§¸ ê²ƒì„ ì‚¬ìš©
                        for elem in elements:
                            elem_text = elem.text.strip()
                            if elem_text: # ë¹„ì–´ìˆì§€ ì•Šì€ í…ìŠ¤íŠ¸ ë°œê²¬
                                content_text = elem_text
                                logger.info(f"âœ… ë‚´ìš© ì¶”ì¶œ ì„±ê³µ (ì„ íƒì: '{selector}') (URL: {link})")
                                break # ë‚´ë¶€ ë£¨í”„(elements) íƒˆì¶œ
                        if content_text:
                            break # ì™¸ë¶€ ë£¨í”„(selectors) íƒˆì¶œ
                except Exception as e_select:
                    logger.warning(f"âš ï¸ ì„ íƒì '{selector}' ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë˜ëŠ” ìš”ì†Œ ì—†ìŒ (URL {link}): {str(e_select)}")
            
            if not content_text:
                logger.warning(f"â‰ï¸ ìœ„ ì„ íƒìë“¤ë¡œ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (URL: {link}). í˜ì´ì§€ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
                # ëŒ€ì²´: bodyì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                try:
                    content_text = driver.find_element("css selector", "body").text.strip()
                    if not content_text:
                         content_text = "[ë³¸ë¬¸ ë‚´ìš© ì—†ìŒ - ëª¨ë“  ì„ íƒì ì‹¤íŒ¨ ë° body ë¹„ì–´ìˆìŒ]"
                except Exception as e_body:
                    logger.error(f"âŒ Body í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ (URL {link}): {str(e_body)}")
                    content_text = "[ë³¸ë¬¸ ë‚´ìš© ì—†ìŒ - Body ì ‘ê·¼ ë¶ˆê°€]"

            logger.info(f"ğŸƒâœ¨ğŸ‰ğŸŠ ìµœì¢… ì»¨í…ì¸  í…ìŠ¤íŠ¸: {content_text}")
            return content_text

        except Exception as e:
            logger.error(f"âŒâŒâŒ Selenium í¬ë¡¤ë§ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ ({link}): {str(e)}")
            # page_source = driver.page_source if driver else "ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì•ˆë¨"
            # logger.debug(f"ì˜¤ë¥˜ ë°œìƒ ì‹œì ì˜ í˜ì´ì§€ ì†ŒìŠ¤ (ì²˜ìŒ 1000ì):\n{page_source[:1000]}")
            return f"[Selenium í¬ë¡¤ë§ ì˜¤ë¥˜]: {str(e)}"

        finally:
            if driver:
                driver.quit()
                logger.info(f"ğŸ§¹ Selenium WebDriver ì¢…ë£Œë¨ (URL: {link})")

    # ... [get_news_content (ì •ì ), analyze_esg_keywords, generate_wordcloud_image ê°™ì€ ë‹¤ë¥¸ ë©”ì†Œë“œë“¤]
    # ... ì›Œë“œí´ë¼ìš°ë“œ ë‹¤ì‹œ í™œì„±í™” ì‹œ FONT_PATHê°€ ì •í™•í•œì§€ í™•ì¸



    # def get_news_content(self, url: str) -> str:
    #     """ê° ë‰´ìŠ¤ ë§í¬ì—ì„œ ë³¸ë¬¸ í¬ë¡¤ë§"""
    #     try:
    #         response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
    #         response.raise_for_status()
    #         soup = BeautifulSoup(response.content.decode('utf-8', 'replace'), "html.parser") # utf-8 ë””ì½”ë”© ëª…ì‹œ

    #         # ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ ì„ íƒì (ë‹¤ì–‘í•œ êµ¬ì¡°ì— ëŒ€ì‘)
    #         # ìš°ì„ ìˆœìœ„: #articleBodyContents (êµ¬ë²„ì „), #dic_area (ì¼ë°˜), article (HTML5 ì‹œë§¨í‹± íƒœê·¸)
    #         content_selectors = [
    #             '#articleBodyContents',
    #             '#dic_area',
    #             'article#dic_area', # ì¢€ ë” ëª…í™•í•œ ì„ íƒ
    #             'div.article_body', # ë‹¤ë¥¸ ì–¸ë¡ ì‚¬ í¬ë§·
    #             'div.newsct_body', # ë‹¤ë¥¸ ì–¸ë¡ ì‚¬ í¬ë§·
    #             'article'
    #         ]
    #         article = None
    #         for selector in content_selectors:
    #             article = soup.select_one(selector)
    #             if article:
    #                 break
            
    #         content = ""
    #         if article:
    #             # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (ê´‘ê³ , ê´€ë ¨ë‰´ìŠ¤ ë“±)
    #             tags_to_remove = ['script', 'style', 'iframe', 'footer', 'header', 'aside', '.link_news', '.promotion', '.journalist_info']
    #             for tag_selector in tags_to_remove:
    #                 for unwanted_tag in article.select(tag_selector):
    #                     unwanted_tag.decompose()
    #             content = article.get_text(separator="\n", strip=True)
    #         else:
    #             content = "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ (ì„ íƒì ë¶ˆì¼ì¹˜)"
            
    #         # logger.info(f"ğŸ“„ URL '{url}' ë³¸ë¬¸ ì¶”ì¶œ ê²°ê³¼: {content[:200]}...") # ë„ˆë¬´ ê¸¸ì–´ì„œ ì¼ë¶€ë§Œ ë¡œê¹…
    #         return content

    #     except requests.Timeout:
    #         logger.error(f"âŒ ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œê°„ ì´ˆê³¼: {url}")
    #         return "ë³¸ë¬¸ í¬ë¡¤ë§ ì‹œê°„ ì´ˆê³¼"
    #     except Exception as e:
    #         logger.error(f"âŒ ë‰´ìŠ¤ ë³¸ë¬¸ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ({url}): {str(e)}")
    #         return f"ë³¸ë¬¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}"
            

    # def analyze_esg_keywords(self, contents: list) -> dict:
    #     """ë‰´ìŠ¤ ë³¸ë¬¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ESG í‚¤ì›Œë“œ ë“±ì¥ ë¹ˆë„ ë¶„ì„"""
    #     esg_keywords_path = "app/domain/service/esg_keywords.txt" # ê²½ë¡œ ìˆ˜ì •
    #     try:
    #         with open(esg_keywords_path, "r", encoding="utf-8") as file:
    #             esg_keywords = [line.strip() for line in file.readlines() if line.strip()]
    #         logger.info(f"ğŸ”‘ ESG í‚¤ì›Œë“œ {len(esg_keywords)}ê°œ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ: {esg_keywords_path}")
    #     except FileNotFoundError:
    #         logger.error(f"âŒ ESG í‚¤ì›Œë“œ íŒŒì¼({esg_keywords_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    #         return {"error": f"ESG í‚¤ì›Œë“œ íŒŒì¼({esg_keywords_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}


    #     combined_text = " ".join(contents)
    #     if not combined_text.strip():
    #         logger.warning("âš ï¸ ë¶„ì„í•  í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
    #         return {}
            
    #     word_freq = Counter()

    #     for word in esg_keywords:
    #         count = combined_text.count(word)
    #         if count > 0:
    #             word_freq[word] = count
        
    #     logger.info(f"ğŸ“Š ESG í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ ì™„ë£Œ: {dict(word_freq)}")
    #     return dict(word_freq)

    # def generate_wordcloud_image(self, word_freq: dict) -> str:
    #     """
    #     ë‹¨ì–´ ë¹ˆë„ìˆ˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ 
    #     Base64ë¡œ ì¸ì½”ë”©ëœ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    #     """
    #     if not word_freq:
    #         logger.info("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    #         return "" # ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€/ê¸°ë³¸ ì´ë¯¸ì§€ Base64 ë°˜í™˜ ê°€ëŠ¥

    #     try:
    #         # WordCloud ê°ì²´ ìƒì„±
    #         # Macì—ì„œ Brewë¡œ fontconfig ì„¤ì¹˜ ì‹œ /opt/homebrew/etc/fonts/conf.d ê²½ë¡œì— í°íŠ¸ ì„¤ì •ì´ ìˆì„ ìˆ˜ ìˆìŒ
    #         # Dockerfileì— ì§€ì •ëœ í°íŠ¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    #         wc = WordCloud(
    #             font_path=FONT_PATH,
    #             width=800,
    #             height=400,
    #             background_color="white",
    #             max_words=100 # í‘œì‹œí•  ìµœëŒ€ ë‹¨ì–´ ìˆ˜
    #         ).generate_from_frequencies(word_freq)

    #         # ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜ í›„ ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼ì— ì €ì¥
    #         img_byte_arr = io.BytesIO()
    #         wc.to_image().save(img_byte_arr, format='PNG')
    #         img_byte_arr = img_byte_arr.getvalue()

    #         # Base64ë¡œ ì¸ì½”ë”©
    #         img_base64 = base64.b64encode(img_byte_arr).decode('utf-8')
    #         logger.info("ğŸ–¼ï¸ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ìƒì„± ë° Base64 ì¸ì½”ë”© ì„±ê³µ")
    #         return img_base64
    #     except Exception as e:
    #         # í°íŠ¸ ê²½ë¡œ ë¬¸ì œ ë°œìƒ ì‹œ ì—¬ê¸°ì„œ ì—ëŸ¬ ë¡œê¹… ê°€ëŠ¥
    #         logger.error(f"âŒ ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    #         logger.error(f"â„¹ï¸ ì‚¬ìš©ëœ í°íŠ¸ ê²½ë¡œ: {FONT_PATH}")
    #         # í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° OSError: cannot open resource ë°œìƒ ê°€ëŠ¥
    #         if "cannot open resource" in str(e) or "No such file or directory" in str(e):
    #              logger.error("ğŸ†˜ í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Dockerfileì— í°íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€, FONT_PATHê°€ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”.")
    #         return "" # ë˜ëŠ” ì—ëŸ¬ ì²˜ë¦¬ì— ë§ëŠ” ê°’ ë°˜í™˜